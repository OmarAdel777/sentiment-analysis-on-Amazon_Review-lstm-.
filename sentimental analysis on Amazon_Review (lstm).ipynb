{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Importing Libraries and modules"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import re\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from sklearn.metrics import confusion_matrix, classification_report\n","from tensorflow.keras.optimizers import SGD, Adam\n","import bz2\n","import csv\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"markdown","metadata":{},"source":["## Reading function for data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read(text):\n","    data = bz2.BZ2File(text)\n","    data = data.readlines()\n","    data = [x.decode('utf-8') for x in data]\n","    return data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T09:53:59.130542Z","iopub.status.busy":"2023-11-05T09:53:59.129662Z","iopub.status.idle":"2023-11-05T09:55:37.068181Z","shell.execute_reply":"2023-11-05T09:55:37.067177Z","shell.execute_reply.started":"2023-11-05T09:53:59.130508Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3600000\n","400000\n"]}],"source":["training_data=read(\"D:/AI/Electropi/5.Deep Neural Networks [NN2]/4. Poem Text Generation/Capstones/Data/Amazon_review/train.ft.txt.bz2\"\n",")\n","testing_data=read(\"D:/AI/Electropi/5.Deep Neural Networks [NN2]/4. Poem Text Generation/Capstones/Data/Amazon_review/test.ft.txt.bz2\"\n",")\n","\n","print(len(training_data))\n","print( len(testing_data))"]},{"cell_type":"markdown","metadata":{},"source":["## Extracting Training and Testing data & and assigning the labels"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T09:55:37.070221Z","iopub.status.busy":"2023-11-05T09:55:37.069946Z","iopub.status.idle":"2023-11-05T09:55:52.992150Z","shell.execute_reply":"2023-11-05T09:55:52.991401Z","shell.execute_reply.started":"2023-11-05T09:55:37.070196Z"},"trusted":true},"outputs":[],"source":["\n","def extraction(training_data, testing_data):\n","    # Split the data into labels and texts\n","    training_labels = [int(re.findall(r'__label__(\\d)', line)[0]) for line in training_data]\n","    training_texts = [re.sub(r'__label__\\d ', '', line) for line in training_data]\n","\n","    testing_labels = [int(re.findall(r'__label__(\\d)', line)[0]) for line in testing_data]\n","    testing_texts = [re.sub(r'__label__\\d ', '', line) for line in testing_data]\n","    \n","    return training_labels, training_texts, testing_labels, testing_texts\n","\n","def convert(training_labels, testing_labels):\n","    # Convert training labels to binary (0 and 1)\n","    training_labels = [0 if label == 1 else 1 for label in training_labels]\n","    \n","    # Convert test labels to binary (0 and 1)\n","    testing_labels = [0 if label == 1 else 1 for label in testing_labels]\n","    \n","    return training_labels, testing_labels\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T09:55:52.993713Z","iopub.status.busy":"2023-11-05T09:55:52.993335Z","iopub.status.idle":"2023-11-05T10:04:39.337540Z","shell.execute_reply":"2023-11-05T10:04:39.336688Z","shell.execute_reply.started":"2023-11-05T09:55:52.993678Z"},"trusted":true},"outputs":[],"source":["# Tokenization and padding\n","\n","training_labels, training_texts, testing_labels, testing_texts = extraction(training_data, testing_data)\n","training_labels, testing_labels = convert(training_labels, testing_labels)\n","\n","print(\"Training Labels:\", len(training_labels))\n","print(\"Training Texts:\", len(training_texts))\n","print(\"Test Labels:\", len(testing_labels))\n","print(\"Test Texts:\", len(testing_texts))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T10:04:39.340716Z","iopub.status.busy":"2023-11-05T10:04:39.340367Z","iopub.status.idle":"2023-11-05T10:04:40.390585Z","shell.execute_reply":"2023-11-05T10:04:40.389537Z","shell.execute_reply.started":"2023-11-05T10:04:39.340687Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3600000, 100)\n","(400000, 100)\n","(3600000,)\n","(400000,)\n"]}],"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","# Tokenization and padding\n","max_words = 1000\n","max_sequence_length = 100\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(training_texts)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(training_texts)\n","X_test_sequences = tokenizer.texts_to_sequences(testing_texts)\n","\n","# Pad sequences to a fixed length\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n","X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n","\n","# Convert to NumPy arrays\n","X_train = np.array(X_train_padded)\n","X_test = np.array(X_test_padded)\n","\n","# Print shapes\n","print( X_train.shape)\n","print( X_test.shape)\n","\n","# Convert labels to NumPy arrays\n","y_train = np.array(training_labels)\n","y_test = np.array(testing_labels)\n","\n","# Print shapes\n","print( y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T10:37:02.814312Z","iopub.status.busy":"2023-11-05T10:37:02.813929Z","iopub.status.idle":"2023-11-05T11:15:00.179818Z","shell.execute_reply":"2023-11-05T11:15:00.178979Z","shell.execute_reply.started":"2023-11-05T10:37:02.814285Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1758/1758 [==============================] - 170s 95ms/step - loss: 0.6929 - accuracy: 0.5342\n","Epoch 2/5\n","1758/1758 [==============================] - 167s 95ms/step - loss: 0.6924 - accuracy: 0.5758\n","Epoch 3/5\n","1758/1758 [==============================] - 167s 95ms/step - loss: 0.6915 - accuracy: 0.6016\n","Epoch 4/5\n","1758/1758 [==============================] - 167s 95ms/step - loss: 0.6867 - accuracy: 0.6088\n","Epoch 5/5\n","1758/1758 [==============================] - 168s 95ms/step - loss: 0.6321 - accuracy: 0.6386\n","12500/12500 [==============================] - 74s 6ms/step - loss: 0.5966 - accuracy: 0.6793\n","Epoch 1/5\n","1758/1758 [==============================] - 253s 141ms/step - loss: 0.4056 - accuracy: 0.8182\n","Epoch 2/5\n","1758/1758 [==============================] - 248s 141ms/step - loss: 0.3493 - accuracy: 0.8407\n","Epoch 3/5\n","1758/1758 [==============================] - 248s 141ms/step - loss: 0.3300 - accuracy: 0.8503\n","Epoch 4/5\n","1758/1758 [==============================] - 248s 141ms/step - loss: 0.2391 - accuracy: 0.9047\n","Epoch 5/5\n","1758/1758 [==============================] - 248s 141ms/step - loss: 0.2609 - accuracy: 0.9060\n","12500/12500 [==============================] - 106s 8ms/step - loss: 0.3078 - accuracy: 0.9090\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense\n","from keras.optimizers import SGD, Adam\n","\n","def create_model(optimizer, activation_function, lstm_layers, max_words, max_sequence_length):\n","    # Define the model architecture\n","    model = Sequential()\n","    model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n","    for _ in range(lstm_layers):\n","        model.add(LSTM(128, return_sequences=True))\n","    model.add(LSTM(128, return_sequences=False))\n","    model.add(Dense(1, activation=activation_function))\n","    \n","    # Compile the model with binary cross-entropy loss and the specified optimizer\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    \n","    return model\n","\n","# Define different configurations for the models\n","configurations = [\n","    {\"optimizer\": SGD(learning_rate=0.01), \"activation_function\": 'sigmoid', \"lstm_layers\": 1},\n","    {\"optimizer\": Adam(learning_rate=0.001), \"activation_function\": 'relu', \"lstm_layers\": 2},\n","]\n","\n","results = []\n","\n","# Train and evaluate models for each configuration\n","for i, config in enumerate(configurations, 1):\n","    print(f\"Training model {i}/{len(configurations)}...\")\n","    \n","    # Create a model based on the current configuration\n","    model = create_model(config[\"optimizer\"], config[\"activation_function\"], config[\"lstm_layers\"], max_words, max_sequence_length)\n","    \n","    # Train the model on training data (X_train, y_train) for 5 epochs\n","    # using a batch size of 2048 and verbose training output\n","    model.fit(X_train, y_train, epochs=5, batch_size=2048, verbose=1)\n","    \n","    # Evaluate the trained model on the test data (X_test, y_test)\n","    loss, accuracy = model.evaluate(X_test, y_test)\n","    \n","    # Store the configuration, loss, and accuracy in the results list\n","    results.append({\"config\": config, \"loss\": loss, \"accuracy\": accuracy})\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T11:15:00.182184Z","iopub.status.busy":"2023-11-05T11:15:00.181891Z","iopub.status.idle":"2023-11-05T11:15:00.188053Z","shell.execute_reply":"2023-11-05T11:15:00.187162Z","shell.execute_reply.started":"2023-11-05T11:15:00.182159Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Configuration: Optimizer=<keras.optimizers.sgd.SGD object at 0x7fdc344021d0>, Activation=sigmoid, LSTM Layers=1\n","Test Loss: 0.5965809226036072, Test Accuracy: 0.6793274879455566\n","\n","Configuration: Optimizer=<keras.optimizers.adam.Adam object at 0x7fdc8261f5b0>, Activation=relu, LSTM Layers=2\n","Test Loss: 0.3077607750892639, Test Accuracy: 0.9090175032615662\n","\n"]}],"source":["for result in results:\n","    config = result[\"config\"]\n","    loss = result[\"loss\"]\n","    accuracy = result[\"accuracy\"]\n","    print(f\"Configuration: Optimizer={config['optimizer']}, Activation={config['activation_function']}, LSTM Layers={config['lstm_layers']}\")\n","    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\\n\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T11:15:55.988899Z","iopub.status.busy":"2023-11-05T11:15:55.988528Z","iopub.status.idle":"2023-11-05T11:17:40.831858Z","shell.execute_reply":"2023-11-05T11:17:40.830809Z","shell.execute_reply.started":"2023-11-05T11:15:55.988870Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12500/12500 [==============================] - 96s 8ms/step\n","Confusion Matrix:\n","[[176474  23526]\n"," [ 12867 187133]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.88      0.91    200000\n","           1       0.89      0.94      0.91    200000\n","\n","    accuracy                           0.91    400000\n","   macro avg       0.91      0.91      0.91    400000\n","weighted avg       0.91      0.91      0.91    400000\n","\n"]}],"source":["# Evaluate with a confusion matrix and classification report\n","y_pred = model.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","report = classification_report(y_test, y_pred)\n","print(\"Classification Report:\")\n","print(report)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
